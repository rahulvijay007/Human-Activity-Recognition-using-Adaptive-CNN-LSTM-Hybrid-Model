{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3105ded5",
   "metadata": {
    "id": "3105ded5"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e4c1c4",
   "metadata": {
    "id": "51e4c1c4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torchvision.transforms.functional import to_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfffe85",
   "metadata": {
    "id": "1bfffe85"
   },
   "source": [
    "# Define dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182bdb14-e1c9-4769-950a-0569b00730e9",
   "metadata": {
    "id": "182bdb14-e1c9-4769-950a-0569b00730e9"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/content/drive/MyDrive/har_dataset/train'\n",
    "TEST_DIR = '/content/drive/MyDrive/har_dataset/test'\n",
    "\n",
    "TRAIN_CSV = '/content/drive/MyDrive/har_dataset/Training_set.csv'\n",
    "TEST_CSV = '/content/drive/MyDrive/har_dataset/Testing_set.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898407b",
   "metadata": {
    "id": "8898407b"
   },
   "source": [
    "# Load CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5f1d24-a023-464a-bde0-e6a2da127750",
   "metadata": {
    "id": "4b5f1d24-a023-464a-bde0-e6a2da127750"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/har_dataset/Training_set.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m train_df.sample(frac=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m test_df = pd.read_csv(TEST_CSV)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/drive/MyDrive/har_dataset/Training_set.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df.sample(frac=0.2, random_state=42).reset_index(drop=True)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e6d6f",
   "metadata": {
    "id": "106e6d6f"
   },
   "source": [
    "# Inspect basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec11f0e-7a82-440d-8b75-e79142bf4b32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ec11f0e-7a82-440d-8b75-e79142bf4b32",
    "outputId": "83fdcee9-59c7-4d15-e1e1-02ae01abf649"
   },
   "outputs": [],
   "source": [
    "print(\"ðŸ”Ž Training Data Sample:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nðŸ§¼ Missing Values:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8b038",
   "metadata": {
    "id": "06f8b038"
   },
   "source": [
    "# Analyze class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31864da1-32ba-4a91-bb36-88a936d3d174",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31864da1-32ba-4a91-bb36-88a936d3d174",
    "outputId": "60c7f695-c529-4955-bb81-a0022fcebf92"
   },
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Class Distribution:\")\n",
    "class_counts = train_df['label'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f6b96-35f2-4f8f-be65-266e0f1987cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "c20f6b96-35f2-4f8f-be65-266e0f1987cf",
    "outputId": "5504f5c2-5319-4959-cef6-11b938869db8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=train_df, x='label', order=class_counts.index, palette='viridis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Training Data Class Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33f570",
   "metadata": {
    "id": "7d33f570"
   },
   "source": [
    "# Image property check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d660c-e8df-4acd-8448-5f2560d4b753",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "834d660c-e8df-4acd-8448-5f2560d4b753",
    "outputId": "a2efaba2-cce4-476e-e04d-1b427f481821"
   },
   "outputs": [],
   "source": [
    "sample_image_path = os.path.join(TRAIN_DIR, train_df.iloc[0]['filename'])\n",
    "img = Image.open(sample_image_path)\n",
    "print(f\"ðŸ–¼ï¸ Sample Image Size: {img.size}, Mode: {img.mode}\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf545d",
   "metadata": {
    "id": "31cf545d"
   },
   "source": [
    "# Display sample images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf9f3a-57db-40ec-ab46-966e660a5c4e",
   "metadata": {
    "id": "08cf9f3a-57db-40ec-ab46-966e660a5c4e"
   },
   "outputs": [],
   "source": [
    "def show_samples(df, data_dir, n=5):\n",
    "    unique_labels = df['label'].unique()\n",
    "    fig, axes = plt.subplots(len(unique_labels), n, figsize=(n*3, len(unique_labels)*3))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        sample_imgs = df[df['label'] == label].sample(n=n, random_state=42)\n",
    "        for j, img_name in enumerate(sample_imgs['filename']):\n",
    "            img_path = os.path.join(data_dir, img_name)\n",
    "            image = Image.open(img_path)\n",
    "            axes[i][j].imshow(image)\n",
    "            axes[i][j].axis('off')\n",
    "            if j == 0:\n",
    "                axes[i][j].set_ylabel(label, rotation=0, size='large')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be439d8-1750-4e06-bcbc-70ad52e80b9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8be439d8-1750-4e06-bcbc-70ad52e80b9b",
    "outputId": "fe65c7b6-51cb-4a53-bc77-33b81ed9f40a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"ðŸ“· Sample images from each class:\")\n",
    "show_samples(train_df, TRAIN_DIR, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d6414",
   "metadata": {
    "id": "c93d6414"
   },
   "source": [
    "# Encode labels for model compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c03fc-25fc-42d4-94c5-c359b0c20815",
   "metadata": {
    "id": "ab0c03fc-25fc-42d4-94c5-c359b0c20815"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['label_encoded'] = label_encoder.fit_transform(train_df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655f471-a025-465a-a292-15c2ac6c3a03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2655f471-a025-465a-a292-15c2ac6c3a03",
    "outputId": "917e6b79-5b3d-4ee6-ffaa-f1e35b3fffcd"
   },
   "outputs": [],
   "source": [
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"ðŸ§¾ Label Map:\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83b178-4c63-46b0-b51a-8438bf266cd9",
   "metadata": {
    "id": "2e83b178-4c63-46b0-b51a-8438bf266cd9"
   },
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e62b2-6d1b-4d30-8421-adb39f53c607",
   "metadata": {
    "id": "740e62b2-6d1b-4d30-8421-adb39f53c607"
   },
   "outputs": [],
   "source": [
    "label_map_clean = {str(k): int(v) for k, v in label_map.items()}\n",
    "\n",
    "with open(\"label_map.json\", \"w\") as f:\n",
    "    json.dump(label_map_clean, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03e6b9",
   "metadata": {
    "id": "9e03e6b9"
   },
   "source": [
    "# Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623f2b9-b03e-401b-8727-955601b6a47d",
   "metadata": {
    "id": "9623f2b9-b03e-401b-8727-955601b6a47d"
   },
   "outputs": [],
   "source": [
    "class HARImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.df.loc[idx, 'filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # PIL image\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply Resize, ToTensor, Normalize in one go\n",
    "\n",
    "        label = torch.tensor(self.df.loc[idx, 'label_encoded'], dtype=torch.long)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a34023",
   "metadata": {
    "id": "88a34023"
   },
   "source": [
    "# Instantiate Dataset & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec8eb8-cd8f-4a20-9e79-fe6b166e121e",
   "metadata": {
    "id": "a9ec8eb8-cd8f-4a20-9e79-fe6b166e121e"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbbe398-8d37-48b6-a625-dda3218a2e40",
   "metadata": {
    "id": "8cbbe398-8d37-48b6-a625-dda3218a2e40"
   },
   "outputs": [],
   "source": [
    "train_dataset = HARImageDataset(train_df, TRAIN_DIR, transform=image_transforms)\n",
    "test_dataset = HARImageDataset(test_df, TEST_DIR, transform=image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b72ea4-c5ab-4cf9-b44a-0a131f63c6e5",
   "metadata": {
    "id": "e8b72ea4-c5ab-4cf9-b44a-0a131f63c6e5"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d914c2f3-75d4-4d6e-b484-25dd043d13a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d914c2f3-75d4-4d6e-b484-25dd043d13a1",
    "outputId": "f846a594-ba3d-450b-c557-ad6dc9b1c82a"
   },
   "outputs": [],
   "source": [
    "print(\"âœ… Step 2 complete: Custom dataset and dataloaders ready for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a197b5",
   "metadata": {
    "id": "b8a197b5"
   },
   "source": [
    "# Quick Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6acfd5-f905-4844-9f79-64a738d3f890",
   "metadata": {
    "id": "bd6acfd5-f905-4844-9f79-64a738d3f890"
   },
   "outputs": [],
   "source": [
    "def visualize_batch(data_loader, label_decoder):\n",
    "    batch = next(iter(data_loader))\n",
    "    images, labels = batch\n",
    "    images = images[:6]\n",
    "    labels = labels[:6]\n",
    "\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(15,3))\n",
    "    for i in range(6):\n",
    "        img = images[i].permute(1, 2, 0) * 0.5 + 0.5\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(label_decoder[labels[i].item()])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f20d7",
   "metadata": {
    "id": "233f20d7"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e469b-ddef-4875-8941-c7a3795be244",
   "metadata": {
    "id": "cc9e469b-ddef-4875-8941-c7a3795be244"
   },
   "outputs": [],
   "source": [
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, num_classes=15, lstm_hidden_size=64, lstm_layers=1, dropout=0.5):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "\n",
    "\n",
    "        base_model = models.mobilenet_v2(pretrained=True)\n",
    "        self.cnn_backbone = base_model.features\n",
    "\n",
    "\n",
    "        self.flatten_spatial = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),\n",
    "            nn.Flatten(start_dim=2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1280,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * lstm_hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.cnn_backbone(x)\n",
    "        x = self.flatten_spatial(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]\n",
    "\n",
    "        out = self.classifier(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76713e08",
   "metadata": {
    "id": "76713e08"
   },
   "source": [
    "# Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262985e-a386-4d42-ab20-6509845d34de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e262985e-a386-4d42-ab20-6509845d34de",
    "outputId": "69028b9a-b756-4a36-e8b3-364bde801983"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4de3e-b0df-4f2b-9404-254a3ce6d398",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfc4de3e-b0df-4f2b-9404-254a3ce6d398",
    "outputId": "001b1fdc-fcee-4017-e1b3-f2c3a8021663"
   },
   "outputs": [],
   "source": [
    "model = CNNLSTMModel(num_classes=15)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f3662",
   "metadata": {
    "id": "a58f3662"
   },
   "source": [
    "# Setup Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4f584-f5f2-4ecb-9080-3bcb6898651a",
   "metadata": {
    "id": "01e4f584-f5f2-4ecb-9080-3bcb6898651a"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed600f6",
   "metadata": {
    "id": "3ed600f6"
   },
   "source": [
    "# Helper: Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed69d24-b9ea-436c-8acd-e36adfee4897",
   "metadata": {
    "id": "4ed69d24-b9ea-436c-8acd-e36adfee4897"
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    return torch.sum(preds == labels).item() / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bed506",
   "metadata": {
    "id": "16bed506"
   },
   "source": [
    "# Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b72394-324b-4449-a39c-5da8764982ff",
   "metadata": {
    "id": "84b72394-324b-4449-a39c-5da8764982ff"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, running_acc = 0.0, 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_acc += accuracy(outputs, labels) * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_acc / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916116e0-bf77-4cf5-8e27-bb173082e24e",
   "metadata": {
    "id": "916116e0-bf77-4cf5-8e27-bb173082e24e"
   },
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, running_acc = 0.0, 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_acc += accuracy(outputs, labels) * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_acc / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaaae3-a9e6-4857-8878-bc63808b3577",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aedaaae3-a9e6-4857-8878-bc63808b3577",
    "outputId": "8a83a4e2-125b-4168-d2c0-1dca6263851e"
   },
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36064b80",
   "metadata": {
    "id": "36064b80"
   },
   "source": [
    "# Master Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33db67-772d-45e8-8442-65fa4d5fb00a",
   "metadata": {
    "id": "0f33db67-772d-45e8-8442-65fa4d5fb00a"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "best_val_acc = 0.0\n",
    "save_path = 'best_cnn_lstm_model.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575dd59-e868-4984-b11a-75c4757024aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a575dd59-e868-4984-b11a-75c4757024aa",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "72f9ff89-d231-4adb-814d-496ff244bc08"
   },
   "outputs": [],
   "source": [
    "def get_subset_loader(dataset, fraction=0.2):\n",
    "    size = int(len(dataset) * fraction)\n",
    "    indices = torch.randperm(len(dataset))[:size]\n",
    "    subset = torch.utils.data.Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loader_subset = get_subset_loader(test_dataset, fraction=0.2)\n",
    "    val_loss, val_acc = validate_one_epoch(model, val_loader_subset, criterion, device)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521456b",
   "metadata": {
    "id": "2521456b"
   },
   "source": [
    "# Visualizing Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595ddc5-aedf-427a-a0f1-78a4c7e893e9",
   "metadata": {
    "id": "9595ddc5-aedf-427a-a0f1-78a4c7e893e9"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(train_losses, val_losses, train_accs, val_accs):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14,6))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, train_accs, 'bo-', label='Train Accuracy')\n",
    "    plt.plot(epochs, val_accs, 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ea9d5",
   "metadata": {
    "id": "0d3ea9d5"
   },
   "source": [
    "# Advanced Metrics â€” Precision, Recall, F1, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f5921-fab0-462f-90fd-4116ddec9946",
   "metadata": {
    "id": "dc3f5921-fab0-462f-90fd-4116ddec9946"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c50685a",
   "metadata": {
    "id": "5c50685a"
   },
   "source": [
    "# Inference on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886b57f-ed52-49ed-8003-c7ce6b612c1e",
   "metadata": {
    "id": "a886b57f-ed52-49ed-8003-c7ce6b612c1e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_image(model, image_path, device, class_names):\n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "    return class_names[pred.item()]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
